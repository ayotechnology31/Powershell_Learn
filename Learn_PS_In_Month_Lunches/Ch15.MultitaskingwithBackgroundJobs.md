Everyone’s always telling you to “multitask,” right? Why shouldn’t PowerShell help
you out with that by doing more than one thing at a time? It turns out that PowerShell can do exactly that, particularly for longer-running tasks that might involve
multiple target computers. Make sure you’ve read chapters 13 and 14 before you
dive into this chapter, because we’ll be taking those remoting and WMI concepts a
step farther.
15.1 Making PowerShell do multiple things
at the same time
You should think of PowerShell as a single-threaded application, meaning that it
can do only one thing at once. You type a command, you hit Return, and the shell
waits for that command to execute. You can’t run a second command until the first
command finishes.
 But with its background jobs functionality, PowerShell has the ability to move a
command onto a separate background thread (a separate, background PowerShell
process). That enables the command to run in the background, as you continue to
use the shell for some other task. But you have to make that decision before running the command; after you press Return, you can’t decide to move a longrunning command into the background.

Synchronous versus asynchronous 183
 After commands are in the background, PowerShell provides mechanisms to
check on their status, retrieve any results, and so forth.
15.2 Synchronous versus asynchronous
Let’s get a few bits of terminology out of the way first. PowerShell runs normal commands synchronously, meaning you hit Return and then wait for the command to complete. Moving a job into the background allows it to run asynchronously, meaning you
can continue to use the shell for other tasks as the command completes.
 Let’s look at some important differences between running commands in these
two ways:
 When you run a command synchronously, you can respond to input requests.
When you run commands in the background, there’s no opportunity to see
input requests—in fact, they’ll stop the command from running.
 Synchronous commands produce error messages when something goes wrong.
Background commands produce errors, but you won’t see them immediately.
You’ll have to make arrangements to capture them, if necessary. (Chapter 22
discusses how you do that.)
 If you omit a required parameter on a synchronous command, PowerShell can
prompt you for the missing information. On a background command, it can’t,
so the command will fail.
 The results of a synchronous command start displaying as soon as they become
available. With a background command, you wait until the command finishes
running and then retrieve the cached results.
We typically run commands synchronously to test them out and get them working properly, and only run them in the background after we know they’re fully debugged and
working as we expect. We follow these measures to ensure the command will run without problems, and that it will have the best chance of completing in the background.
 PowerShell refers to background commands as jobs, and you can create jobs in several ways, and there are several commands you can use to manage them.
Above and beyond
Technically, the jobs we’ll discuss in this chapter are just one kind of job you’ll
encounter. Jobs are an extension point for PowerShell, meaning it’s possible for
someone (either in Microsoft or as a third party) to create other things called jobs
that look and work a bit differently than what we’ll describe in this chapter. In fact,
scheduled jobs, which we’ll cover later in this chapter, work a bit differently than the
“normal” jobs that we’ll cover first, and you may run into other kinds of jobs as you
extend the shell for different purposes. We want you to know that little detail, and to
know that what you’re learning applies only to the native, regular jobs that come with
PowerShell.

184 CHAPTER 15 Multitasking with background jobs
15.3 Creating a local job
The first type of job we’ll cover is perhaps the easiest: a local job. This is a command
that runs more or less entirely on your local computer (with exceptions that we’ll
cover in a second) and that runs in the background.
 To launch one of these jobs, you use the Start-Job command. A -scriptblock
parameter lets you specify the command (or commands) to run. PowerShell will make
up a default job name (Job1, Job2, and so on), or you can specify a custom job name by
using the -Name parameter. If you need the job to run under alternative credentials, a
-credential parameter will accept a DOMAIN\Username credential and prompt you
for the password. Rather than specifying a script block, you can specify the -FilePath
parameter to have the job execute an entire script file full of commands.
 Here’s a simple example:
PS C:\> start-job -scriptblock { dir }
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
1 Job1 Running True localhost
The result of the command is the job object that was created, and as the previous
example shows, the job begins running immediately. The job is also assigned a
sequential job ID number, which is shown in the table.
 We said these jobs run entirely on your local computer, and that’s true. But the
commands in the job are allowed to access remote computers, which would be the
case if you ran a command that supported a -computerName parameter. Here’s an
example:
PS C:\> start-job -scriptblock {
➥get-eventlog security -computer server-r2
}
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
3 Job3 Running True localhost
TRY IT NOW We hope you’ll follow along and run all of these commands. If
you only have a single computer to work with, refer to its computer name and
use localhost as an alternative, so that PowerShell will act like it’s dealing with
two computers.
The processing for this job will happen on your local computer. It will contact the
specified remote computer (SERVER-R2 in this example), so the job is, in a way, a
“remote job.” But because the command itself is running locally, we still refer to this as
a local job.
 Sharp-eyed readers will note that the first job we created was named Job1 and
given the ID 1, but the second job was Job3 with ID 3. It turns out that every job has at
least one child job, and the first child job (a child of Job1) was given the name Job2 and
the ID 2. We’ll get to child jobs a bit later in this chapter.

WMI, as a job 185
 Here’s something to keep in mind: although local jobs run locally, they do require
the infrastructure of PowerShell’s remoting system, which we covered in chapter 13. If
you haven’t enabled remoting, you won’t be able to start local jobs.
15.4 WMI, as a job
Another way to start a job is to use Get-WmiObject. As we explained in the previous
chapter, the Get-WmiObject command can contact one or more remote computers,
but it does so sequentially. That means a long list of computer names can cause the
command to take a long time to process, so that command is a natural choice for moving to a background job. To do so, you use Get-WmiObject as usual but add the
-AsJob parameter. You don’t get to specify a custom job name at this point; you’re
stuck with the default job name that PowerShell applies.
TRY IT NOW If you’re running the same commands on your test system, you’ll
need to create a text file called allservers.txt. We put it in the root of our C:
drive (because that’s where we have PowerShell focused for these examples),
and we put several computer names in the file, listing one name per line. You
can list your computer name and localhost to duplicate the results we’re
showing you.
PS C:\> get-wmiobject win32_operatingsystem -computername
➥(get-content allservers.txt) -asjob
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
5 Job5 Running False server-r2,lo...
This time, the shell will create one top-level parent job (Job5, which is shown in the
output of the command), and it will create one child job for each computer that you
specified. You can see that the Location column in the output table lists as many of
the computer names as will fit, indicating that the job will be running against those
computers.
 It’s important to understand that Get-WmiObject executes only on your computer;
the cmdlet is using normal WMI communications to contact the remote computers
you specified. It’ll still do this one at a time and follow the usual defaults of skipping
computers that aren’t available, and so forth. In fact, it works identically to using
Get-WmiObject synchronously, except that the cmdlet runs in the background.
TRY IT NOW You have commands other than Get-WmiObject that can start a
job. Try running Help * -parameter asjob to see if you can find all of them.
Note that the newer Get-CimInstance command, which you learned about in
chapter 14, doesn’t have an -AsJob parameter. If you want to use it in a job, run
either Start-Job or Invoke-Command (which you’ll learn about next), and include
Get-CimInstance (or for that matter, any of the new CIM commands) in the script
block.

186 CHAPTER 15 Multitasking with background jobs
15.5 Remoting, as a job
Let’s review the final technique you can use to create a new job: PowerShell’s remoting capabilities, which you learned about in chapter 13. As with Get-WmiObject, you
start this kind of job by adding an -AsJob parameter, but this time you’ll add it to the
Invoke-Command cmdlet.
 There’s an important difference here: whatever command you specify in the
-scriptblock (or -command, which is an alias for the same parameter) will be transmitted in parallel to each computer you specify. Up to 32 computers can be contacted
at once (unless you modify the -throttleLimit parameter to allow more or fewer), so
if you specify more than 32 computer names, only the first 32 will start. The rest will
start after the first set begins to finish, and the top-level job will show a completed status after all of the computers finish.
 Unlike the other two ways to start a job, this technique requires you to have PowerShell v2 or v3 installed on each target computer, and remoting to be enabled in
PowerShell on each target computer. Because the command physically executes on
each remote computer, you’re distributing the computing workload, which can help
improve performance for complex or long-running commands. The results come
back to your computer and are stored with the job until you’re ready to review them.
 In the following example, you’ll also see the -JobName parameter that lets you
specify a job name other than the boring default:
PS C:\> invoke-command -command { get-process }
➥-computername (get-content .\allservers.txt )
➥-asjob -jobname MyRemoteJob
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
8 MyRemoteJob Running True server-r2,lo...
15.6 Getting job results
The first thing you’ll probably want to do after starting a job is check to see if your jobs
have finished. The Get-Job cmdlet will retrieve every job currently defined by the system, and show you each one’s status:
PS C:\> get-job
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
1 Job1 Completed True localhost
3 Job3 Completed True localhost
5 Job5 Completed True server-r2,lo...
8 MyRemoteJob Completed True server-r2,lo...
You can also retrieve a specific job by using its ID or its name. We suggest that you do
that and pipe the results to Format-List *, because you’ve gathered some valuable
information:

Getting job results 187
PS C:\> get-job -id 1 | format-list *
State : Completed
HasMoreData : True
StatusMessage :
Location : localhost
Command : dir
JobStateInfo : Completed
Finished : System.Threading.ManualResetEvent
InstanceId : e1ddde9e-81e7-4b18-93c4-4c1d2a5c372c
Id : 1
Name : Job1
ChildJobs : {Job2}
Output : {}
Error : {}
Progress : {}
Verbose : {}
Debug : {}
Warning : {}
TRY IT NOW If you’re following along, keep in mind that your job IDs and
names might be a bit different than ours. Focus on the output of Get-Job to
retrieve your job IDs and names, and substitute yours in the examples.
The ChildJobs property is one of the most important pieces of information there is,
and we’ll cover it in a moment.
 To retrieve the results from a job, use Receive-Job. But before you run this, you
need to know a few things:
 You have to specify the job from which you want to receive results. You can do
this by job ID or job name, or by getting jobs with Get-Job and piping them to
Receive-Job.
 If you receive the results of the parent job, those results will include all output
from all child jobs. Alternatively, you can choose to get the results from one or
more child jobs.
 Normally, receiving the results from a job clears them out of the job output
cache, so you can’t get them a second time. Specify -keep to keep a copy of the
results in memory. Or you can output the results to CliXML, if you want to
retain a copy to work with.
 The job results may be deserialized objects, which you learned about in
chapter 13. That means they’re a snapshot from the point in time when they
were generated, and they may not have any methods that you can execute. But
you can pipe the job results directly to cmdlets such as Sort-Object,
Format-List, Export-CSV, ConvertTo-HTML, Out-File, and so on, if desired.
Here’s an example:
PS C:\> receive-job -id 1
 Directory: C:\Users\Administrator\Documents

188 CHAPTER 15 Multitasking with background jobs
Mode LastWriteTime Length Name
---- ------------- ------ ----
d---- 11/21/2009 11:53 AM Integration Services Script C
 omponent
d---- 11/21/2009 11:53 AM Integration Services Script T
 ask
d---- 4/23/2010 7:54 AM SQL Server Management Studio
d---- 4/23/2010 7:55 AM Visual Studio 2005
d---- 11/21/2009 11:50 AM Visual Studio 2008
The preceding output shows an interesting set of results. Here’s a quick reminder of
the command that launched this job in the first place:
PS C:\> start-job -scriptblock { dir }
Although our shell was in the C:\ drive when we ran this, the directory in the results is
C:\Users\Administrator\Documents. As you can see, even local jobs take on a slightly
different context when they run, which may result in a change of location. Don’t ever
make assumptions about file paths from within a background job: use absolute paths
to make sure you can refer to whatever files your job command may require. If we
wanted the background job to get a directory of C:\, we should have run the following
command:
PS C:\> start-job -scriptblock { dir c:\ }
When we received the results from job 1, we didn’t specify -keep. If we try to get those
same results again, we’ll get nothing, because the results are no longer cached with
the job:
PS C:\> receive-job -id 1
PS C:\>
Here’s how you would force the results to stay cached in memory:
PS C:\> receive-job -id 3 -keep
 Index Time EntryType Source InstanceID Messa
 ge
 ----- ---- --------- ------ ---------- -----
 6542 Oct 04 11:55 SuccessA... Microsoft-Windows... 4634 An...
 6541 Oct 04 11:55 SuccessA... Microsoft-Windows... 4624 An...
 6540 Oct 04 11:55 SuccessA... Microsoft-Windows... 4672 Sp...
 6539 Oct 04 11:54 SuccessA... Microsoft-Windows... 4634 An...
You’ll eventually want to free up the memory that’s being used to cache the job
results, and we’ll cover that in a bit. But first, let’s look at a quick example of piping
the job results directly to another cmdlet:
PS C:\> receive-job -name myremotejob | sort-object PSComputerName |
➥Format-Table -groupby PSComputerName
 PSComputerName: localhost

Working with child jobs 189
Handles NPM(K) PM(K) WS(K) VM(M) CPU(s) Id ProcessN PSCompu
 ame terName
------- ------ ----- ----- ----- ------ -- -------- -------
 195 10 2780 5692 30 0.70 484 lsm loca...
 237 38 40704 36920 547 3.17 1244 Micro... loca...
 146 17 3260 7192 60 0.20 3492 msdtc loca...
 1318 100 42004 28896 154 15.31 476 lsass loca...
This was the job we started by using Invoke-Command. As always, the cmdlet has added
the PSComputerName property so we can keep track of which object came from which
computer. Because we retrieved the results from the top-level job, this included all of
the computers we specified, which allows this command to sort them on the computer
name and then create an individual table group for each computer.
Get-Job can also keep you informed about which jobs have results remaining:
PS C:\> get-job
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
1 Job1 Completed False localhost
3 Job3 Completed True localhost
5 Job5 Completed True server-r2,lo...
8 MyRemoteJob Completed False server-r2,lo...
The HasMoreData column will be False when no output is cached with that job. In
the case of Job1 and MyRemoteJob, we have already received those results and didn’t
specify -keep at that time.
15.7 Working with child jobs
We mentioned earlier that all jobs consist of one top-level parent job and at least one
child job. Let’s look at a job again:
PS C:\> get-job -id 1 | format-list *
State : Completed
HasMoreData : True
StatusMessage :
Location : localhost
Command : dir
JobStateInfo : Completed
Finished : System.Threading.ManualResetEvent
InstanceId : e1ddde9e-81e7-4b18-93c4-4c1d2a5c372c
Id : 1
Name : Job1
ChildJobs : {Job2}
Output : {}
Error : {}
Progress : {}
Verbose : {}
Debug : {}
Warning : {}



TRY IT NOW Don’t follow along for this part, because if you’ve been following
along up to now, you’ve already received the results of Job1. If you’d like to
try this, start a new job by running Start-Job -script { Get-Service }, and
use that new job’s ID instead of the ID number 1 we used in our example.
You can see that Job1 has a child job, Job2. You can get it directly now that you know
its name:
PS C:\> get-job -name job2 | format-list *
State : Completed
StatusMessage :
HasMoreData : True
Location : localhost
Runspace : System.Management.Automation.RemoteRunspace
Command : dir
JobStateInfo : Completed
Finished : System.Threading.ManualResetEvent
InstanceId : a21a91e7-549b-4be6-979d-2a896683313c
Id : 2
Name : Job2
ChildJobs : {}
Output : {Integration Services Script Component, Integration Servic
 es Script Task, SQL Server Management Studio, Visual Studi
 o 2005...}
Error : {}
Progress : {}
Verbose : {}
Debug : {}
Warning : {}
Sometimes, a job will have too many child jobs to list in that form, so you may want to
list them a bit differently, as follows:
PS C:\> get-job -id 1 | select-object -expand childjobs
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
2 Job2 Completed True localhost
This technique will create a table of the child jobs for job ID 1, and the table can be
whatever length it needs to be to list them all.
 You can receive the results from any individual child job by specifying its name or
ID with Receive-Job.
15.8 Commands for managing jobs
Jobs also use three more commands. For each of these, you can specify a job either by
giving its ID, giving its name, or by getting the job and piping it to one of these cmdlets:
 Remove-Job—This deletes a job, and any output still cached with it, from
memory.

 Stop-Job—If a job seems to be stuck, this command will terminate it. You’ll still
be able to receive whatever results were generated to that point.
 Wait-Job—This is useful if a script is going to start a job and you want the script
to continue only when the job is done. This command forces the shell to stop
and wait until the job is completed, and then allows the shell to continue.
For example, to remove the jobs that we’ve already received output from, we’d use the
following command:
PS C:\> get-job | where { -not $_.HasMoreData } | remove-job
PS C:\> get-job
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
3 Job3 Completed True localhost
5 Job5 Completed True server-r2,lo...
Jobs can also fail, meaning that something went wrong with their execution. Consider
this example:
PS C:\> invoke-command -command { nothing } -computer notonline -asjob -job
name ThisWilLFail
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
11 ThisWilLFail Failed False notonline
Here, we started a job with a bogus command and targeted a non-existent computer.
The job immediately failed, as shown in its status. We don’t need to use Stop-Job at
this point; the job isn’t running. But we can get a list of its child jobs:
PS C:\> get-job -id 11 | format-list *
State : Failed
HasMoreData : False
StatusMessage :
Location : notonline
Command : nothing
JobStateInfo : Failed
Finished : System.Threading.ManualResetEvent
InstanceId : d5f47bf7-53db-458d-8a08-07969305820e
Id : 11
Name : ThisWilLFail
ChildJobs : {Job12}
Output : {}
Error : {}
Progress : {}
Verbose : {}
Debug : {}
Warning : {}
And we can then get that child job:

PS C:\> get-job -name job12
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
12 Job12 Failed False notonline
As you can see, no output was created for this job, so you won’t have any results to
retrieve. But the job’s errors are stored in the results, and you can get them by using
Receive-Job:
PS C:\> receive-job -name job12
Receive-Job : [notonline] Connecting to remote server failed with the foll
owing error message : WinRM cannot process the request. The following erro
r occured while using Kerberos authentication: The network path was not fo
und.
The full error is much longer; we’ve truncated it here to save some space. You’ll notice
that the error includes the computer name that the error came from, [notonline].
What happens if only one of the computers can’t be reached? Let’s try:
PS C:\> invoke-command -command { nothing }
➥-computer notonline,server-r2 -asjob -jobname ThisWilLFail
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
13 ThisWilLFail Running True notonline,se...
After waiting for a bit, we’ll run the following:
PS C:\> get-job
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
13 ThisWilLFail Failed False notonline,se...
The job still failed, but let’s look at the individual child jobs:
PS C:\> get-job -id 13 | select -expand childjobs
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
14 Job14 Failed False notonline
15 Job15 Failed False server-r2
OK, they both failed. We have a feeling we know why Job14 didn’t work, but what’s
wrong with Job15?
PS C:\> receive-job -name job15
Receive-Job : The term 'nothing' is not recognized as the name of a cmdlet
, function, script file, or operable program. Check the spelling of the na
me, or if a path was included, verify that the path is correct and try aga
in.

Ah, that’s right, we told it to run a bogus command. As you can see, each child job can
fail for different reasons, and PowerShell will track each one individually.
15.9 Scheduled jobs
PowerShell v3 introduces support for scheduled jobs—a PowerShell-friendly way of
creating tasks in Windows’ Task Scheduler. These jobs work differently from the jobs
we’ve discussed up to this point; as we wrote earlier, jobs are an extension point in
PowerShell, meaning there can be many kinds of job that work slightly differently.
The scheduled jobs feature is one of those different kinds of job.
 You start a scheduled job by creating a trigger (New-JobTrigger) that defines when
the task will run. You can also set options for the job (New-ScheduledTaskOption).
Then you register the job (Register-ScheduledJob) with Task Scheduler. This creates
the job definition in Task Scheduler’s XML format, on disk, and creates a folder hierarchy to contain the results of the job each time it runs.
 Let’s look at an example:
PS C:\> Register-ScheduledJob -Name DailyProcList -ScriptBlock { Get-Proces
s } -Trigger (New-JobTrigger -Daily -At 2am) -ScheduledJobOption (New-Sched
uledJobOption -WakeToRun -RunElevated)
WARNING: column "Enabled" does not fit into the display and was removed.
Id Name JobTriggers Command
-- ---- ----------- -------
1 DailyProcList {1} Get-Process
This creates a new job that will run Get-Process every day at 2 a.m., waking the computer if necessary, and running under elevated privileges. After the job runs, you can
come back into PowerShell and run Get-Job to see a standard job for each time the
scheduled task completed:
PS C:\> get-job
WARNING: column "Command" does not fit into the display and was removed.
Id Name State HasMoreData Location
-- ---- ----- ----------- --------
6 DailyProcList Completed True localhost
9 DailyProcList Completed True localhost
Unlike normal jobs, receiving the results from scheduled jobs won’t delete the results,
because they’re cached on disk and not in memory. You can continue to receive the
results over and over. When you remove the job, the results will be removed from disk,
too. As shown in figure 15.1, this output resides in a specific folder on disk, and
Receive-Job is capable of reading those files.
 You can control the number of stored result sets by using the -MaxResultCount
parameter of Register-ScheduledJob.


15.10 Common points of confusion
Jobs are usually straightforward, but we’ve seen folks do one thing that does cause
confusion. Don’t do this:
PS C:\> invoke-command -command { Start-Job -scriptblock { dir } }
➥-computername Server-R2
Doing so starts up a temporary connection to SERVER-R2 and starts a local job. Unfortunately, that connection immediately terminates, so you have no way to reconnect and
retrieve that job. In general, then, don’t mix and match the three ways of starting jobs.
 The following is also a bad idea:
PS C:\> start-job -scriptblock { invoke-command -command { dir }
➥-computername SERVER-R2 }
That’s completely redundant; keep the Invoke-Command section and use the -AsJob
parameter to have it run in the background.
 Less confusing, but equally interesting, are the questions our classroom students
often ask about jobs. Probably the most important of these is, “Can we see jobs started
by someone else?” The answer is no, except for scheduled jobs. Normal jobs are contained entirely within the PowerShell process, and although you could see that
Figure 15.1 Scheduled job output is stored on disk


another user was running PowerShell, you wouldn’t be able to see inside that process.
It’s like any other application: you could see that another user was running Microsoft
Office Word, for example, but you couldn’t see what documents they were editing,
because those documents exist entirely inside of Word’s process.
 Jobs only last as long as your PowerShell session is open. After you close it, any jobs
defined within it disappear. Jobs aren’t defined anywhere outside of PowerShell, so
they depend upon its process continuing to run in order to maintain themselves.
 Scheduled jobs are the exception to the previous statement: anyone with permission can see them, modify them, delete them, and retrieve their results, because
they’re stored on disk. Note that they’re stored under your user profile, so it would
normally require an administrator to get the files (and results) out of your profile.



15.11 Lab
NOTE For this lab, you’ll need a Windows 8 or Windows Server 2012 computer running PowerShell v3.
The following exercises should help you understand how to work with the different
types of jobs and tasks in PowerShell. As you work through these exercises, don’t feel
you have to write a one-line solution. Sometimes it’s easier to break things down into
separate steps.

1 Create a one-time background job to find all the PowerShell scripts on the C:
drive. Any task that might take a long time to complete is a great candidate for a
job.
Start-Job {dire c:\ -resume -filter '*.ps1'}

2 You realize it would be helpful to identify all PowerShell scripts on some of your
servers. How would you run the same command from task 1 on a group of
remote computers?
Invoke-Command -scriptblock {dir c:\ -recurse -filter *.ps1}
-computername (get-content computers.txt) -asjob

3 Create a background job that will get the latest 25 errors from the system event
log on your computer and export them to a CliXML file. You want this job to
run every day, Monday through Friday at 6:00 a.m., in order for it to be ready
for you to look at when you come in to work.
$Trigger=New-JobTrigger -At "6:00AM" -DaysOfWeek "Monday","Tuesday", "Wednesday", "Thursday", "Friday" - Weekly $command={ Get-EventLog -LogName System -Newest 25 -EntryType Error | Export-Clixml c:\work\25SysErr.xml}
Register-ScheduledJob -Name "Get 25 System Errors" -ScriptBlock
$Command -Trigger $Trigger
#check on what was created
Get-ScheduledJob | Select *

4 What cmdlet would you use to get the results of a job, and how would you save
the results in the job queue?
Recieve-Job -id 1 -keep
